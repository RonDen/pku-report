
\section{主要内容}

% >  密码脱离实践，大型的提供商使用智能的后端服务来在不完美身份认证技术中获得生存的理论
标题：密码和不完美身份认证的演化过程

文章内容：尽管研究者都普遍认为需要有一些更加安全且用户友好的措施来取代密码，但是密码确实已经统治人机身份认证超过50年了。近期出版的很多工作集中在那些可以被形式化表示的问题上，但是对保护用户隐私和敏感数据没有特别的帮助。学术界一般推崇严格的密码组合策略，比如说长度要求、强制要求数字和非字母字符，但是很少有证据能表明这样能够减少对攻击者的危害，这是学术界与应用脱节的一个例子。

在本文中作者强调了将身份认证视为一个整体重新审视的重要性以及密码的作用。作者指出了两种实际上已经过时了但是依然被使用的模型：1）一个随机用户模型，用户总是均匀地、独立地从可能的密码集合中选取自己的密码。这通常会导致对密码抗猜测攻击安全性的高估，并且会鼓励很多实际上无效的选取用户密码的措施。2）密码文件离线攻击。这个模型相对于其他威胁（比如客户端上的恶意软件、钓鱼、信道监听、后端明文泄露，这些更难去分析但是在实践意义上更为重要），过分强调了一个在猜测攻击上不可攻破的密码的重要性。综合起来，上面两个过时的模型导致了许多矛盾的建议使得正常人很难遵守。

研究者大都关注一个清晰的、定义良好的问题，导致了对网络身份认证上大量的、复杂的、杂乱的真实问题的忽视。研究重心的错误持续阻碍了密码研究在实践上的可用性。因为没有辨别出网络身份认证上广泛的可用性，可部署性和安全性的挑战，对用户产生了大量的不合适的密码需求，并且许多研究人员做出无数的尝试来在各种变化多端的应用找到一个万全的解决方法。但是实际上没有一种单一的技术可以在所有情况下完美地“解决”身份验证问题，需要各种技术协同地组合，工业界早已在朝着这个方向发展。许多领先的提供商使用多个并行的互补身份验证机制来支持而不是替换密码。通常使用机器学习将这些结合在一起，以便将成本和给用户带来的不方便最小化，同时为电子商务和在线社交互动提供足够的安全以促进繁荣。我们希望认证即使在技术上可能不太先进，也将逐渐变得更加安全且不那么麻烦。这种趋势并非没有缺点。它强烈青睐拥有丰富用户习惯知识的大型提供商。它使身份验证更具侵入性，并且越来越难以为用户和研究人员所理解。我们鼓励研究人员认识到这一趋势，并专注于解决相关的安全性，隐私和可用性挑战。
\subsection{过去的教训}

% > 作为HTTP cookies的交换，输入HTML表单中的基于文本的密码已经成为了一种互联网网络身份认证协议的主流，尽管从未被正式指定。

从最开始，密码就是一个安全的创可贴。（个人理解：是安全的辅助手段而不是主要手段，相当于打补丁）。在1960年代开发第一代分时操作系统的时候，密码被用来防止恶作剧者保护研究者使用更多授权后的资源。MIT的1961年兼容分时系统很可能是第一种以这种方式部署密码的系统。之后立刻出现了安全问题。报道了很多一个用户猜测另外一个用户密码的案例，并且至少有一个泄露了主密码文件，密码是以明文形式存储在其中的。但是，由于所有用户都是同一个学术组织的一部分，因此这些问题很容易通过管理方式解决。

随着1970年代MULTICS和Unix中访问控制的发展，密码被修改以保护敏感数据和计算资源。 MULTICS通过以散列形式存储密码来保护密码，这是1960年代剑桥大学的Roger Needham和Mike Guy发明的一种做法。罗伯特·莫里斯（Robert Morris）和肯·汤普森（Ken Thompson）在1979年对密码安全性的开创性论述描述了通过`crypt()`函数向专用密码哈希和加盐的演变，以及对字典攻击和暴力破解的首次分析。

十年后，1988年的莫里斯（Morris）Internet蠕虫病毒证明了许多系统容易受到密码猜测的影响。管理员通过将密码哈希存储在受更严格保护的shadow密码文件中，有时还主动检查用户密码的可猜测性，从而进行了调整。

1990年代中期，随着互联网和电子商务的出现，人们开始尝试通过安全套接字层（SSL）客户端证书或竞争性的安全电子交易（SET）协议用公钥密码术替换密码。最终，证明对客户端的证书和私钥进行管理非常繁重，市场从未得到发展。相反，Web上的安全连接几乎普遍依赖于经过身份验证的SSL。服务器通过SSL层上的证书进行身份验证，而用户稍后无需明确的协议支持就可以证明其身份。以HTML形式输入的基于文本的密码（用于交换HTTP cookie）已成为用户身份验证的主要协议（尽管从未正式指定）。

随着基于Web的服务的激增，出现了系统密码不存在的可用性问题。重置忘记的密码（以前是IT支持人员的手动任务）通过电子邮件自动进行，从而为大多数用户创建了常见的故障中心。单个用户拥有的帐户数量的增加破坏了每个帐户专用密码的假设，并且密码重用变得司空见惯。网络钓鱼已成为一个主要问题，但是需要更改协议或用户界面的反网络钓鱼提案未能获得采用。相反，主要的对策包括将已知的钓鱼网站列入黑名单，并使用机器学习分类器来识别新的钓鱼网站。

在用户空间中通过身份验证，从而进行专门业务这一尝试多次失败。尽管长期以来一直将部署硬件令牌作为第二个要素，但独立令牌（例如RSA SecurID）在企业环境之外的部署受到限制，这很可能是由于令牌相对于免费在线帐户的价值所致。在为Web提供单点登录的许多尝试中，Microsoft Passport和OpenID未能获得广泛采用。

智能手机的广泛普及可能正在改变这个平衡等式，但是，由于在2010年代初期，包括Facebook，Google和Twitter在内的许多在线服务部署了免费的智能手机应用程序，从而成为基于新兴的基于时间的一次性密码的第二因素。 （TOTP）标准。其他服务通过短消息服务（SMS）发送代码作为备用身份验证机制。一些服务提供了专用令牌作为第二个因素，通常在存在更大欺诈风险的环境中（例如eBay和World of Warcraft）。

\subsection{用户行为的随机模型}
% >除了被视为密码系统中的脆弱链接，用户通常是模型中最复杂的一个组件。

除了被认为是密码系统中的薄弱环节之外，用户通常也是建模最困难的组成部分。理想情况下，他们会选择由随机字符组成的密码。但是，即使承认这是理想化模型的研究人员通常也低估了建模行为与现实之间的差距。安全策略和研究模型在适应新数据源（例如泄漏的密码数据集和大规模测量研究）所揭示的不准确信息的幅度方面一直很缓慢。
关于密码策略的最著名的早期资料之一是美国国防部大约在1985年的《绿皮书》，其中指定了用于减轻密码猜测风险的详细策略，包括速率限制，静态哈希密码和限制密码寿命。绿皮书完全避免了用户行为的复杂性，提出了三个主要原则之一：“由于许多用户创建的密码特别容易猜到，因此所有密码都应由机器生成。”
同年，NIST在联邦信息处理标准（FIPS）系列中发布了其密码使用指南，该指南大量取材于《绿皮书》。除了推荐的机器选择密码之外，FIPS准则还允许用户选择密码，但要注意的是，“如果可能，应指示用户随机使用从所有可接受的密码中选择的一种密码，或者选择一个与之无关的密码”他们的个人身份，历史或环境。”如今，由于人们难以记住机器选择的密码，几乎所有非军事应用都允许用户选择密码。然而，FIPS指南保留了绿皮书中的大多数其他建议，包括根据允许的字符和长度要求计算密码安全性，限制密码使用时间（经常换密码）以及强制更新。这鼓励了一种不切实际的乐观假设，即用户选择密码的方式类似于至今一直存在的随机密码生成器。

通过“熵”估算密码强度。通常通过将密码建模为来自均匀分布的随机选择来估计用户选择密码的猜测阻力。这使得可以按照1985年绿皮书的传统对预期猜测时间进行直接计算。为了试图抓住一个事实，许多用户从相对较少的通用密码中进行选择（尽管从理论上可以选择文本密码的空间很大），研究人员经常选择相对较小的均匀分布。在此模型中，这种均匀分布的大小的对数通常称为“熵”，这是参考克劳德·香农（Claude Shannon）着名的$H_1$来度量的，它编码从分布得出的符号所需的最小平均位数。不幸的是，Shannon熵模拟了攻击者所需的猜测次数，攻击者可以恒定时间检查未知密码是否是任意大小的可能性集的成员。这并不对应于任何真正的猜测攻击。

更为直接的指标是“guesswork”，$G$，即攻击者按顺序猜测各个密码直到找到所有密码的预期查询次数。可以看出，$H_1$提供了$G$的下限。但是，$G$也是有问题的，因为它可能会因稀有但难以猜测的密码而高度偏斜。为了解决这种偏见，已经开发了“部分”（或“边际”）猜测指标。一种表述是部分猜测（$G_{\alpha}$），它模拟攻击者仅进行足够的猜测就具有成功的可能性$\alpha$，这封装了当$\alpha= 1$时的传统$G$，而较低的$\alpha$值则模拟了更真实的攻击者。香农熵已经证明，这样的度量通常不会降低界限。尽管部分猜测指标提供了密码猜测难度的适当数学模型，但它们需要非常大的样本才能准确估计，通常为数百万个密码，因此实际使用受到限制。

对于较小的数据集，通常需要采用启发式方法来衡量密码强度。 NIST的《电子认证指南》（从许多方面对《绿皮书》进行了更新）承认了香农熵在数学上的不合理性，但仍引入了一种启发式方法来估算各种组合策略下密码分配的“熵”（NIST熵）。此模型已在许多学术研究中使用，尽管在实践中发现它得出的估计相对不准确。尽管取决于特定工具的配置，但是首选的经验方法是针对一组密码简单地运行流行的开源密码破解库，并评估找到给定比例密码所需要的平均猜测数。这种方法甚至可以应用于单个密码来评估其相对强度，尽管相对于使用更有利的破解库的任何真实对手而言，这显然高估了安全性。

提高密码强度。诸如Shannon和NIST熵之类的简单措施使密码强度的提高似乎非常接近。如果密码是随机的，则增加密码的最小长度或扩展字符类别的组合策略似乎会导致这些措施的可靠增加；例如，NIST指南建议至少要求使用一个大写字母和非字母Betic字符。尽管承认用户可以将其插入可预测的位置，但与允许任何密码的策略相比，指南仍估计密码的猜测难度增加了六位（或64的倍数）。但是，实验表明，这可能被高估了一个数量级。

尽管存在高昂的可用性成本，但这种密码策略仍然存在，但稍后将进行讨论，尽管可以说，在竞争激烈的网站（例如网络邮件提供商）上，它们的使用要比竞争少的网站（例如大学和政府服务）少得多。相反，研究表明，最有效的策略只是使用大型黑名单来限制最常见密码的频率，将在线猜测攻击的边界限制在可预测的水平，并承认许多用户会选择容易被猜测的密码。

一个相关的目标是通过反馈（例如图形仪表，指示用户选择的密码强度）来促使用户使用更好的密码。在实验设置中，非常激进的强度计会使猜测用户选择的密码变得更加困难。但是，在使用实际使用的典型仪表的研究中，没有提示用户考虑密码的用户，仪表的影响可以忽略不计。许多用户根本没有注意到他们。雅虎（Yahoo!）提供了一个经验数据点，在该处添加密码强度表确实可以提高密码安全性，但仅能带来一点点改善。

选择多个密码时独立。随机用户模型通常还假定将独立选择每个密码。实际上，在Web上很少如此，因为用户可以通过密码重用来应付大量的帐户，有时只需稍作修改即可。例如，一项2007年的遥测研究估计，中位用户拥有受密码保护的帐户，但只有六个唯一的密码。这直接影响安全性，因为一个网站上的漏洞可能损害另一个网站的安全性。即使用户没有完全重用密码，攻击者也可以猜测较小的变化，这可能会使在线猜测情况下成功的机会翻倍。选择相关的密码同样会破坏强制密码更新的安全性目标，因为知道用户的先前密码序列的攻击者通常可以轻松猜出下一个密码。

\subsection{离线威胁VS.在线威胁}

% >只有当攻击者获取到了密码文件，合适的哈希与加盐和密码的长度才真正起作用。

安全相关的文献将需要与合法方进行交互以进行身份验证视为在线攻击者，与之区分的是仅在计算资源方面受到限制的离线攻击者。
从表面上看，离线攻击者的功能要强大得多，因为他们通常可以进行无数猜测，并将其与已知的密码哈希进行比较。但是在线攻击者还可以使用许多其他攻击途径：使用客户端恶意软件窃取密码，使用欺骗性网站诱骗密码，在传输密码时窃听密码，从身份验证服务器窃取密码，从第二秒窃取密码用户重用的身份验证服务器，并破坏了自动密码重置过程。

一个关键的观察结果是，强密码并不能帮助抵御其他任何攻击。即使最强的密码仍然是可以重现的静态的秘密，同样容易受到网络钓鱼，盗窃和窃听的攻击。强制使用更强的密码对于提高抗此类攻击的安全性毫无帮助。

*离线猜测（破解）*。人们一直致力于设计策略来选择足够复杂的密码，以抵制恶意破解。然而，这种对策最多只能在很少的情况下阻止现实世界的破坏。对于无法访问密码文件的攻击者，任何猜测都必须在线进行，并且是存在速率限制的。如果一个被泄露的密码文件中的密码是没有被哈希计算的，那么无论它们有多复杂都是以明文形式暴露了；如果哈希了但是未加盐，则使用大的“彩虹表”就能通过蛮力查找找到一定长度内的密码（个人理解：这时候长度就起作用了）。 然而，尽管哈希和加盐长期以来一直被安全专业人员视为最佳实践，但它们还远未普及。根据经验估计，超过40％的网站未加密存储密码；最近的大规模密码泄露表明，许多漏洞是纯文本（例如RockYou和Tianya），散列但未加盐的（例如LinkedIn），散列不适当的（例如Gawker）或可逆加密的（例如Adobe）。

最后，如果攻击者的违法行为被检测出来了，则可能会打断的攻击者，管理员可以强迫受影响的用户重置其密码。由于担心丢失用户，通常不会在受到破坏的网站上设置密码；对于密码可能已从可能已被重复使用的受感染第三方网站泄漏的用户而言，它们的授权更为常见。

*在线猜测*。在线攻击者只能通过将其提交给身份验证服务器来验证给定的密码猜测是否正确。可以发送的猜测数量有限。粗略的“三击”模型是抑制攻击的一种明显方式，但是相对很少的站点实施这种确定性策略，可能是为了避免拒绝服务。

尽管如此，在猜测的基础上，在线猜测攻击在某些方面要比离线攻击要昂贵得多。当然，攻击者可能在单台主机上检查十亿次猜测，而在线攻击者可能需要数千个主机。首先，如果我们假设发送数百万次失败尝试的IP地址将被阻止，则必须分配负载。同样，负载可能会超过合法流量；在具有一百万用户的服务中，平均用户每天登录一次，一共10亿个猜测（每个帐户一千个猜测）与三年内合法用户产生的登录请求一样多。如果合法用户在5％左右的时间内（由于打字错误或遗忘）导致失败，则攻击者将产生与合法人口在60年内产生的失败事件一样多的失败事件。

因此，选择一个密码来抵御恶意攻击比选择一个密码来抵御在线攻击要困难得多。然而，只有在可能发生精细攻击的非常有限的情况下，额外的努力才能获得回报。当恶意攻击与其他媒介（例如恶意软件）相形见绌时，专注于这种风险几乎没有任何意义。

\subsection{如今“过度受限”的世界}

% > 有针对性的攻击，包括“高级持续性威胁”，技术复杂，针对单个用户帐户，是最困难的挑战，因为它们可以根据受害者调整技术，为分类器留下相对较少的信息。

与其他选择相比，密码具有引人注目的经济优势，具有最低的启动速度和每用户增量成本。很大程度上由于其作为现有解决方案的地位，它们还具有明显的“可部署性”优势（例如向后兼容性，互操作性和无迁移成本）。但是，不仅仅是这些因素会影响它们的寿命。 “密码替换问题”既未得到充分说明，又受到过度约束。

它没有得到充分的认可，因为没有一套涵盖各种环境，技术平台，文化和应用程序的普遍同意的具体要求。例如，许多身份验证建议在带触摸屏的移动设备上变得完全不可行，现在许多亚洲语言的输入带有持续的图形反馈，必须在输入密码时将其禁用，许多大型网站必须同时支持低价值的论坛帐户和重要的电子商务或网络邮件通过单个系统进行帐户。同时，它的局限性在于，不能期望有一个解决方案能够满足从金融保护到隐私保护的所有要求。可用性，可部署性和安全性要求的列表太长了（很少明确记录）。

使用比较标准框架对提议的密码替代方案进行了深入审查，发现没有任何提议在所有方面都胜过密码。密码似乎是帕累托平衡，要求放弃一些理想的属性$X$以获得任何新的收益$Y$，这使得密码很难替换。

回顾这些密码替代品与常规密码相比的类别如何产生洞察力。密码管理器（可以记住并自动为用户键入密码的软件）在通常情况下可以提高安全性和可用性，但对于用户跨所有用户代理进行配置构成挑战。此问题还影响某些图形密码方案，而其他问题则提供的安全性不足以克服抵抗变化的惯性。除了重要的部署障碍外，生物识别方案似乎还不太适合Web身份验证的无监督环境。欺诈者可以只重播指纹或虹膜图案的数字表示。使用硬件令牌或移动电话生成一次性访问代码的方案可能具有很大的安全优势，但由于可用性问题和成本的综合考虑，普遍采用的方案仍然难以实现。

联合身份验证或“单点登录”协议（其中通过委派给中央身份提供商对用户进行身份验证）可以显着减少密码问题，而又不能完全消除它们。然而，除了引入严重的隐私问题外，他们还无法提供足够吸引依赖站点的商业模型。迄今为止最成功的部署是Facebook Connect（OAuth的一种版本），它通过向用户提供用户数据来激励依赖方，这使得Facebook作为唯一的身份提供者发挥了核心作用，而隐私的保护却微不足道。

没有明显的赢家能够满足所有条件，惯性就成为一个很大的障碍，并且甲板上堆满了希望完全替换密码的技术。更好的选择是根据组织的优先级和使用情况确定竞争需求的优先级，并逐步采用。鉴于它们作为基本的用户身份验证机制得到普遍支持，因此密码首先被明智地实现，它提供了一种最廉价的方式来启动和运行一个想法，而这个想法还没有得到证实，并且安全性还不是很关键，没有学习上的曲折或互操作性的障碍。较低的采用成本也适用于新站点的用户，他们在探索不确定会返回的新站点时需要较低的壁垒。金融网站是罕见的例外，除了法定资本和用户的帐户都具有明显的价值外。

潜在替代品的挑战清单还在继续。尽管可用性下降，但提高安全性可能意味着将潜在的新用户（有时是现有用户）流失给竞争对手。有些替代方案要求各个独立方对服务器或客户端软件进行修改，并且通常是最卖座的。其他一些人则期望大量用户改变其现有习惯或接受培训以使用新机制。但是，有些只是部分解决方案，或仅解决部分安全威胁；有些则仅是部分解决方案。尽管采用了新的和不同的方式，但有些甚至不那么用户友好。而且，如前所述，有些成本更高，并带来其他部署挑战（例如互操作性，与现有基础架构的兼容性以及痛苦的迁移）。

\subsection{给用户的建议}

用户面临很多关于密码的建议：每个帐户使用一个不同的密码；经常更换它们；混合使用字母，标点，符号和数字；使它们至少八个字符长；避免使用个人信息（例如姓名和生日）；不要写下来这些建议共同构成了不切实际的负担，有时相互矛盾。不能期望一个人为每个50个帐户记住一个不同的复杂密码，更不用说轮流更改所有密码了。普遍的看法将安全专家的密码建议概括为“选择一些您不记得的东西，并且不要写下来。”

每条建议都可能对特定威胁有用，这会促使安全专业人员提供这些建议，以试图掩盖自己的基础，并避免对任何潜在的安全漏洞负责，无论给用户带来了不便。预计这种方法会因“合规预算”模型而导致失败，在该模型中，每个用户遵守烦人的安全要求的意愿是一种有限的，可耗尽的资源，应与任何其他预算一样谨慎地进行管理。实际上，用户可以自由使用钱包进行投票的网站（例如在线商店）比用户“被俘虏”的网站（例如大学）更谨慎地选择不超过客户的合规预算。

有用的安全建议需要成熟的风险管理观点，并对与每个对策相关的风险和成本进行粗略的量化。它还需要确认，使用当今部署的密码，用户几乎无法控制最重要的对策。尤其是，运行没有恶意软件的个人计算机可能是最重要的步骤，尽管它具有挑战性，并且经常被密码建议所忽略，但密码建议的概念更简单，但重要性却远不如此。同样，如前所述，在服务器端良好的速率限制和入侵检测也很关键，但是用户除了光顾实施更好的站点外，没有其他代理机构。

正如通常所建议的那样，选择非常强壮的密码的好处要有限得多。在实践中减少伤害的证据还难以捉摸。如前所述，密码破解很少是攻击中的关键步骤。因此，使密码足够强大以抵御专用的破解攻击似乎对除最关键的Web帐户以外的所有帐户都没有回报。对于重要的帐户，密码选择建议应鼓励熟人不容易猜到并且足以承受合理数量的在线猜测（可能是一百万次猜测）的密码。大约一半的用户已经在该栏的上方，但是建议不要通过建议，强度表和黑名单来阻止简单的词典密码，以帮助其他人。

避免重用密码的建议也很常见。虽然它可以很好地防御跨站点密码泄露，但对于大多数用户而言，它与记住密码不兼容。更好的建议可能是避免对重要帐户重用密码，而不用担心对攻击者（或其所有者）而言价值不大的大量帐户。

此外，我们认为针对网络写密码的建议已过时。涉及“监视器上的便笺”的故事通常是指企业密码，用户不会对其安全性有任何个人利益。大多数用户都知道，记下的密码应保存在钱包或其他人通常无法使用的安全地方，即使是熟人。需要注意的是，如果书面密码鼓励用户避免使用非常弱的密码，那么这是一个值得权衡的选择。密码管理器可以是一个更好的折衷方案，可以提高可用性（不记住，不键入），并且可以为每个帐户使用不同的强密码。但是，由于基于电子邮件的密码重置的普遍性，它们可能会带来单点故障，尽管可能不比Web帐户脆弱。

\subsection{多种维度的未来}

我们似乎陷入了替换密码的棘手难题与它们日益增加的不安全性和用户负担之间。许多研究人员预测，大坝将很快破裂，整个行业仅需支付必要的费用来更换密码。但是，这些预测已经进行了十多年。

使用似乎是“破损”的技术来了解大型服务提供商如何管理的关键是网站不需要完善。帐户遭到入侵的问题只是垃圾邮件，网络钓鱼，点击欺诈，僵尸程序，伪造帐户，诈骗和付款欺诈等多种形式的滥用之一。他们中的任何一个都没有在技术上被彻底击败，但是所有这些都得到了有效管理，足以保持运行。

几乎在每种情况下，从技术上“解决”问题的技术都已经失去了以统计学方式进行管理的技术；例如，尽管提出了许多终止垃圾邮件的建议，包括防止域溢出和对发送的每封电子邮件进行微收费的加密协议，但大多数电子邮件提供商已经选择了基于已知攻击者行为模式对邮件进行分类的方法。这些防御措施不是免费的，也不是易于实施的，大型Web运营商通常会投入大量资源来跟上滥用行为的发展。但是，最终，此成本通常远远低于要求用户更改行为的任何方法。

在身份验证的情况下，银行提供了不完善技术的现成示例。尽管信用卡号本质上是静态机密，用户没有试图对商人隐瞒，但后端分类程序将欺诈行为保持在可接受的水平。诸如“芯片和PIN”之类的技术并不是部署的灵丹妙药。卡仍然被盗，可以猜测或观察到PIN，签名交易仍然作为后备，并且没有PIN的在线支付或“卡不存在”交易仍然很普遍。

然而，银行可以通过非二进制身份验证模型来生存，在该模型中，尽力而为地考虑每笔交易的所有可用信息。 Web身份验证正在一种相似的模式上收敛，密码作为不完善的信号而持续存在，并由许多其他方式补充。

\subsection{将Web身份认证视为分类问题}

在幕后，许多大型网站已经过渡到基于风险的用户身份验证模型。这种方法在2000年代初出现在在线金融站点。虽然密码错误意味着应该拒绝访问，但是正确的密码只是分类器可以用来确定身份验证尝试是否涉及真实帐户所有者的一种信号或功能。
除密码外，分类器还可以利用许多信号，包括用户的IP地址。地理位置浏览器信息，包括cookie；登录时间；密码的输入方式；以及正在请求什么资源。与密码不同，这些隐式信号无需用户付出额外的努力即可使用。移动设备从测量用户交互的传感器中引入了许多新信号。尽管这些信号都不是不可伪造的，但每个信号都是有用的。例如，确定的广告商可能会伪造地理位置信息，而浏览器指纹识别技术似乎是一场无休止的军备竞赛。尽管如此，两者在多维解决方案中可能都是有价值的，因为在实践中伪造所有信号的难度可能很大。例如，通过合并120个此类信号，谷歌报告称，2013年被垃圾邮件发送者入侵的帐户数量减少了99.7\%。

与传统的密码身份验证不同，结果不是二进制的，而是对尝试是真实的可能性的实值估计。通常，这些结果将被离散化，因为必须授予用户是否访问某些资源的权限，并且任何分类程序都不可避免地会产生错误的接受和错误的拒绝错误。站点将继续开发其机器学习技术以减少这些错误，并可能部署新技术（例如两因素身份验证和原始绑定证书）以增加可用信号的数量（和质量）。

Web身份验证绝不是解决机器学习问题的简单领域。错误接受和错误拒绝之间的权衡很难正确解决。对于金融网站，错误接受会转化为欺诈，但通常可以通过冲销任何欺诈性付款来恢复。但是，对于那些接受错误结果导致泄露敏感用户数据的站点，永远无法撤销违反机密性的行为，这可能会造成非常高昂的代价。同时，虚假拒绝恼人的客户，他们可能会转向竞争对手。

获取大量具备标签的样本以训练分类器是另一个挑战，因为很难找到管理员尚未知道的攻击示例。具有经济动机的攻击者可能再次最容易处理，因为他们的攻击通常必须具有可伸缩性，从而导致大量攻击，因此需要训练数据。非财务动机的攻击者（例如合作伙伴）可能更难以通过算法进行检测，但用户在现实生活中的定位要好得多。针对性攻击（包括技术上先进且针对单个用户帐户的“高级持续性威胁”）是最困难的挑战，因为攻击者可以为受害者量身定制技术，而分类人员却几乎没有信号。

\subsection{新的操作模式}

通过分类认证从根本上启用了新的操作方法。身份验证可以是一个更灵活的过程，如果分类者的信任度较低或用户尝试进行特别敏感的操作，则需要根据需要提供其他信息，该过程称为“渐进身份验证”。例如，一个站点可能会要求用户通过SMS或电话确认其身份，如果该站点发现其地理位置较远的位置存在可疑的并发活动。当分类者的信度相对较低时，可以为用户提供有限的访问权限，从而实现“多级身份验证”。在英国，一些银行仅向用户提供密码的帐户只读视图，但需要安全令牌才能实际转出资金。

站点也可能会要求较少的信息，包括当它们有合理的把握时，从次要信号中找到正确的用户，包括不需要输入密码。这种形式已经存在：持久会话cookie曾经允许在预定的时间内进行无密码登录，现在由风险分类人员动态地决定何时重新检查密码。更好的版本是机会两因素身份验证，当存在第二个因素时确保正确的身份验证，但是如果密码仍然正确并且提供了足够的附加信号，则启用后备安全性。

这种发展的局限性是“持续认证”。分类员不仅可以在入口处简单地检查密码，还可以在允许用户进入并根据这些附加信号完善其决策后监视用户的行为。最终，连续认证可能意味着认证过程与其他滥用检测系统直接交织在一起。

\subsection{改善用户体验}

由于站点旨在通过机器学习在后端“神奇地”做出正确的身份验证决策，因此用户体验的大多数变化都应该是积极的。普通案件将日益精简；将要求用户尽可能少地键入密码（或采取其他明确的措施）。但是，随着系统变得越来越不透明和难以理解，用户也面临潜在的不利因素。

首先，当分类器的置信度较低时，用户可能会看到更多对第二因素的请求（例如通过SMS的一次性代码）。用户可能还会面临更多的情况（例如在旅行或切换到新计算机时），尽管他们正确记住了密码，但他们仍然无法访问自己的帐户，这与国外出奇的信用卡拒绝类似。拒绝次数的增加可能会增加“后备”身份验证的负担，对此我们仍然缺乏令人满意的解决方案。

随着身份验证系统复杂性的提高，其自动决策可能导致用户增加混乱和困扰。用户不太可能购买任何给他们带来不便之处的系统。培训用户以其凭据响应替代通道上的异步安全性挑战，这也可能为新型网络钓鱼攻击铺平了道路。即使使用了精心设计的用户界面，用户也可能最终对真正的认证仪式感到困惑。

另一个挑战是，更好的分类器可能会在用户逐渐习惯的密码之上打破某些访问控制惯例。例如，如果分类者能够（正确地）确定另一个人正在使用他们的密码，即使他们打算这样做，与配偶或助手共享密码的用户也可能会面临困难。

最后，较少输入密码实际上会降低其可用性，因为如果用户在需要输入密码之间间隔很长时间，则他们很可能会忘记它们。

\subsection{规模的优势}

身份验证可以代表出现在Web上其他地方的赢家通吃特征的经典示例，因为它提供了以两种不同方式进行扩展的好处：首先，大型服务更可能被依赖方接受作为身份验证服务。反过来，被更多依赖方接受会鼓励用户注册帐户，从而进一步增强这些身份提供者对依赖方的吸引力。第二个是“双向市场”，即正反馈回路，用于用户数据。具有更多用户数据的大型服务可以提供更准确的身份验证。这吸引了用户更频繁地与服务交互，从而提供了更多的身份验证数据。开发和维护复杂的基于机器学习的身份验证方法需要相对较高的固定技术成本和较低的每用户边际成本，这进一步有利于最大的身份提供商。

这种合并的结果是，由于缺乏对大型服务提供商所收集的现实世界数据量的访问，独立研究人员在为人工数据集的局限性提供一些重要研究主题的能力上可能受到限制。以及心理推断使以经验为基础的研究至关重要。 Web研究的其他领域（例如，需要大量数据包捕获的网络或需要大量用户查询的搜索引擎研究）对于仅访问公共数据源的研究人员来说同样变得困难。

如果依赖方要求用户使用大型服务进行注册，而大型服务又需要大量个人信息才能很好地执行身份验证，则还存在令人担忧的隐私问题。此信息可能是固有的敏感信息（例如登录活动的时间和位置），也可能难以更改（如果发生泄漏）（例如行为生物特征（如键入模式））。许多用户已经将高度敏感的信息信任大型在线服务，但是身份验证可能是收集更多数据，将其存储更长的时间并与更多方共享的动力。

\subsection{结论}

密码提供了许多理论与实践之间分歧的例子。在理论上有效的强度估计，用户行为模型和密码组成策略通常在实践中没有减少伤害的证据的支持，并且在某些情况下与经验观察直接矛盾。然而，大型Web服务似乎可以应对不安全的密码，这在很大程度上是因为后端的智能技术可以弥补缺点。这是至关重要的（即使是未经宣布的）演进，很大程度上是由行业驱动的，而行业在数据驱动的工程中经验丰富。调整模型和假设以反映这一趋势的研究人员将更有可能提供相关结果。这种发展仍处于早期阶段，关于长期结果，有许多重要而有趣的问题，到目前为止还很少或没有进行研究。在Web上还可以对用户身份验证进行更彻底的重新思考。清理方法对于大型公司而言似乎风险太大，但可以由更加敏捷的学术研究人员探索。应对这些新挑战对于确保已发表的研究领先于行业实践而不是反之亦然很重要。

\section{收获总结}


个人总结：这篇文章\cite{bonneau2015passwords}核心探讨了密码在现实生活中的应用以及遇到的各种问题，归结为不完美身份认证。文章详细讨论了密码做到无法完美认证的困难性，指出了其存在的各种缺点，以及用户在内的许多不可控因素，导致了这种困难性。但同时又指出密码在可见的未来内依然很难被取代，尽管存在很多新的方案，但均不够成熟，密码的使用依然会被保持。同时作者给用户提出了一些提高安全性的建议，并且给研究人员指出了改进的方向。

核心观点：
\begin{itemize}

    \item 过分简化的用户模型和攻击者行为导致研究群体在错误的威胁上进行强调（文中对现行的用户模型和攻击者行为进行了深入的分析，给出的观点更切合实际）。
    \item 因为很多包括密码在内的信息都是可以在互联网上获取的，身份认证可以被视为是一个可以被机器学习处理的分类问题。（个人理解是之前的许多密码泄露事件导致用户口令公布在网上，就形成了一种公开可训练的数据集，当然还有很多用户个人信息等数据，均可以在互联网上获取，成为机器学习模型的输入特征）
    \item  密码在可见的未来内依然是一个很重要的信息，因此我们的目标不是去实现坚不可摧的安全性，而是在可接受的代价范围内减少不完美身份认证带来的损失。（实现一个真正安全的系统是非常难甚至不可能的，但是有很多措施可以在不完全安全的情况下减少损失。）

\end{itemize}


\section{扩展阅读}



扩展阅读了三篇引用了这篇文章的相关论文（引用量较高），其中有两篇的作者是北京大学王平教授，
分别是\cite{wang2016targeted}
和\cite{wang2017zipf}。

其中\cite{wang2016targeted}对在线密码猜测攻击展开了深入研究，提出了一种
具有针对性的TarGuess模型，通过利用受害者的个人信息和个人可识别信息（PII），
能够在较少猜测次数下攻破用户密码。该文章同时指出了互联网密码安全的
一个潜在威胁，并给出了一些实用性的建议。

\cite{wang2017zipf}使用了多种计算统计技术和机器学习模型，探索用户生成密码的基本分布。
这篇文章提出了两个类似Zipf的模型（PDF-Zipf和CDF-Zipf）来表征
密码的分布。在14个包含1.133亿个真实世界密码的数据集上进行试验，
这两种方法能够很好的拟合密码的分布情况。并结合密码分布的具体知识，
提出了一种新的度量密码数据集强度的方法。

\cite{197316}这篇文章更偏向于社会调查，作者对134位参与者进行调研，
探索了有多少用户会在不同的网站上使用相同的密码。结果显示
人们倾向于在1.7-3.4个不同的网站上重复使用相同的密码。
并且大部分人倾向于重复使用需要频繁输入的密码。这说明尽管人们了解
密码安全性，但是他们的自我报告与现实情况相关性不强。



\bibliography{hw2}
